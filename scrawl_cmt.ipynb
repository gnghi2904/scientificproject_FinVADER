{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "# Log In to App: \n",
    "reddit = praw.Reddit(client_id='-1G_AVJTJzG_ILhPlC0r1Q', client_secret='HBAm1HycBjYjvBoUMyFoTDe5opda_g', user_agent='datainneed by u/haizcestlavie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subreddit_submissions(reddit, subreddit_name, text):\n",
    "    # Get the subreddit hot posts\n",
    "    subreddit = reddit.subreddit(subreddit_name).new(limit=1000)\n",
    "\n",
    "    data = []\n",
    "    # Search for the text in the subreddit's submissions\n",
    "    for submission in subreddit:\n",
    "        # Convert the title to lowercase and check if it contains the text\n",
    "        if text.lower() in submission.title.lower():\n",
    "            data.append({\n",
    "                'title': submission.title,\n",
    "                'num_comments': submission.num_comments,\n",
    "                'url': submission.url,\n",
    "                'created': datetime.datetime.fromtimestamp(submission.created),\n",
    "                'upvotes': submission.ups,\n",
    "                'id': submission.id,\n",
    "                'score': submission.score #score is upvotes - downvotes\n",
    "            }) \n",
    "\n",
    "    # Convert the list of dictionaries into a DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(reddit, df):\n",
    "    # Get the list of submission IDs from the DataFrame\n",
    "    submission_ids = df['id'].tolist()\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # Loop over the submission IDs\n",
    "    for submission_id in submission_ids:\n",
    "        # Get the submission\n",
    "        submission = reddit.submission(id=submission_id)\n",
    "        # Get the comments of the submission\n",
    "        submission.comments.replace_more(limit=None)  # This line expands the comment forest if a \"load more comments\" placeholder is encountered\n",
    "        for comment in submission.comments.list():\n",
    "            data.append({\n",
    "                'submission_id': submission_id,\n",
    "                'submission_title': submission.title,\n",
    "                'comment_text': comment.body,\n",
    "                'upvotes': comment.ups\n",
    "            })\n",
    "\n",
    "    # Convert the list of dictionaries into a DataFrame\n",
    "    df_comments = pd.DataFrame(data)\n",
    "    return df_comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 stocks code (TSLA, AMD, AAPL, MSFT, NIO) from subreddit r/wallstreetbets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallstreetbets_df_tsla = get_subreddit_submissions(reddit, 'wallstreetbets', 'tsla')\n",
    "wallstreetbets_df_tsla_comments = get_comments(reddit, wallstreetbets_df_tsla)\n",
    "wallstreetbets_df_tsla_comments\n",
    "wallstreetbets_df_tsla_comments.to_csv('wallstreetbets_tsla_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallstreetbets_df_amd = get_subreddit_submissions(reddit, 'wallstreetbets', 'amd')\n",
    "wallstreetbets_df_amd_comments = get_comments(reddit, wallstreetbets_df_amd)\n",
    "wallstreetbets_df_amd_comments\n",
    "wallstreetbets_df_amd_comments.to_csv('wallstreetbets_amd_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aapl = get_subreddit_submissions(reddit, 'wallstreetbets', 'aapl')\n",
    "df_aapl_comments = get_comments(reddit, df_aapl)\n",
    "df_aapl_comments\n",
    "df_aapl_comments.to_csv('wallstreetbets_aapl_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallstreetbets_df_msft = get_subreddit_submissions(reddit, 'wallstreetbets', 'msft')\n",
    "wallstreetbets_df_msft_comments = get_comments(reddit, wallstreetbets_df_msft)\n",
    "wallstreetbets_df_msft_comments\n",
    "wallstreetbets_df_msft_comments.to_csv('wallstreetbets_msft_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "wallstreetbets_df_nio = get_subreddit_submissions(reddit, 'wallstreetbets', 'nio')\n",
    "wallstreetbets_df_nio_comments = get_comments(reddit, wallstreetbets_df_nio)\n",
    "wallstreetbets_df_nio_comments\n",
    "wallstreetbets_df_nio_comments.to_csv('wallstreetbets_nio_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 stocks code (TSLA, AMD, AAPL, MSFT, NIO) from subreddit r/stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df_tsla = get_subreddit_submissions(reddit, 'stocks', 'tsla')\n",
    "stocks_df_tsla_comments = get_comments(reddit, stocks_df_tsla)\n",
    "stocks_df_tsla_comments\n",
    "stocks_df_tsla_comments.to_csv('stocks_tsla_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df_amd = get_subreddit_submissions(reddit, 'stocks', 'amd')\n",
    "stocks_df_amd_comments = get_comments(reddit, stocks_df_amd)\n",
    "stocks_df_amd_comments\n",
    "stocks_df_amd_comments.to_csv('stocks_amd_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df_aapl = get_subreddit_submissions(reddit, 'stocks', 'aapl')\n",
    "stocks_df_aapl_comments = get_comments(reddit, stocks_df_aapl)\n",
    "stocks_df_aapl_comments\n",
    "stocks_df_aapl_comments.to_csv('stocks_aapl_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df_msft = get_subreddit_submissions(reddit, 'stocks', 'msft')\n",
    "stocks_df_msft_comments = get_comments(reddit, stocks_df_msft)\n",
    "stocks_df_msft_comments\n",
    "stocks_df_msft_comments.to_csv('stocks_msft_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks_df_nio = get_subreddit_submissions(reddit, 'stocks', 'nio')\n",
    "stocks_df_nio_comments = get_comments(reddit, stocks_df_nio)\n",
    "stocks_df_nio_comments\n",
    "stocks_df_nio_comments.to_csv('stocks_nio_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 stocks code (TSLA, AMD, AAPL, MSFT, NIO) from subreddit r/StockMarket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockmarket_df_tsla = get_subreddit_submissions(reddit, 'StockMarket', 'tsla')\n",
    "stockmarket_df_tsla_comments = get_comments(reddit, stockmarket_df_tsla)\n",
    "stockmarket_df_tsla_comments\n",
    "stockmarket_df_tsla_comments.to_csv('stockmarket_tsla_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockmarket_df_amd = get_subreddit_submissions(reddit, 'StockMarket', 'amd')\n",
    "stockmarket_df_amd_comments = get_comments(reddit, stockmarket_df_amd)\n",
    "stockmarket_df_amd_comments\n",
    "stockmarket_df_amd_comments.to_csv('stockmarket_amd_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockmarket_df_aapl = get_subreddit_submissions(reddit, 'StockMarket', 'aapl')\n",
    "stockmarket_df_aapl_comments = get_comments(reddit, stockmarket_df_aapl)\n",
    "stockmarket_df_aapl_comments\n",
    "stockmarket_df_aapl_comments.to_csv('stockmarket_aapl_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockmarket_df_msft = get_subreddit_submissions(reddit, 'StockMarket', 'msft')\n",
    "stockmarket_df_msft_comments = get_comments(reddit, stockmarket_df_msft)\n",
    "stockmarket_df_msft_comments\n",
    "stockmarket_df_msft_comments.to_csv('stockmarket_msft_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stockmarket_df_nio = get_subreddit_submissions(reddit, 'StockMarket', 'nio')\n",
    "stockmarket_df_tsla_nio = get_comments(reddit, stockmarket_df_nio)\n",
    "stockmarket_df_tsla_nio\n",
    "stockmarket_df_tsla_nio.to_csv('stockmarket_nio_comments.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
